language: python
python: "3.6"
env:
  - SPARK_HOME=spark-2.3.1-bin-hadoop2.7
git:
  submodules: false
before_install:
  - sed -i 's/git@github.com:/https:\/\/github.com\//' .gitmodules
  - git submodule update --init --recursive
  - ls -l src/anndata
install:
  - pip install -r requirements.txt
  - |
    if [ ! -d "2.3.1-bin-hadoop2.7" ]; then
      wget http://www-us.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz
      tar xf spark-2.3.1-bin-hadoop2.7.tgz
    fi
script: python test_scanpy_spark.py
cache: pip
cache:
  directories:
    - spark-2.3.1-bin-hadoop2.7
