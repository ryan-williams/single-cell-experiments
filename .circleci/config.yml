version: 2
jobs:
  build:
    working_directory: ~/single-cell-experiments
    docker:
      - image: hancheng/circleci-python3.6-java8:browsers
    environment:
      PYTHONPATH: anndata:scanpy
    steps:
      - checkout
      - run: git submodule sync
      - run: git submodule update --init --recursive
      - run: sudo chown -R circleci:circleci /usr/local/bin
      - run: sudo chown -R circleci:circleci /usr/local/lib/python3.6/site-packages
      - restore_cache:
          key: deps9-{{ .Branch }}-{{ checksum "requirements.txt" }}
      - run:
          command: |
            python3 -m venv venv
            . venv/bin/activate
            echo "PYTHONPATH: $PYTHONPATH"
            pip install -r requirements.txt
            pushd anndata
            pip install -r requires.txt
            popd
      - run:
          command: |
            if [ ! -d "spark-2.3.1-bin-hadoop2.7" ]; then
              wget http://www-us.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz
              tar xf spark-2.3.1-bin-hadoop2.7.tgz
            fi
            export SPARK_HOME=spark-2.3.1-bin-hadoop2.7
            ls venv
      - save_cache:
          key: deps9-{{ .Branch }}-{{ checksum "requirements.txt" }}
          paths:
            - "venv"
            - "/usr/local/bin"
            - "/usr/local/lib/python3.6/site-packages"
            - "spark-2.3.1-bin-hadoop2.7"
      - run:
          command: |
            . venv/bin/activate
            python test_scanpy_spark.py
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test-results
          destination: tr1
