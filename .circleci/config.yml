version: 2
jobs:
  build:
    working_directory: ~/single-cell-experiments
    docker:
      - image: circleci/python:3.6.5
        environment:
          PIPENV_VENV_IN_PROJECT: true
    steps:
      - checkout
      - run: git submodule sync
      - run: git submodule update --init
      - run: sudo chown -R circleci:circleci /usr/local/bin
      - run: sudo chown -R circleci:circleci /usr/local/lib/python3.6/site-packages
      - restore_cache:
          key: deps9-{{ .Branch }}-{{ checksum "requirements.txt" }}
      - run:
          command: |
            python3 -m venv venv
            . venv/bin/activate
            pip install -r requirements.txt
      - run:
          command: |
            if [ ! -d "2.3.1-bin-hadoop2.7" ]; then
              wget http://www-us.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz
              tar xf spark-2.3.1-bin-hadoop2.7.tgz
            fi
            export SPARK_HOME=spark-2.3.1-bin-hadoop2.7
            export SPARK_LOCAL_IP=127.0.0.1
      - save_cache:
          key: deps9-{{ .Branch }}-{{ checksum "requirements.txt" }}
          paths:
            - "venv"
            - "/usr/local/bin"
            - "/usr/local/lib/python3.6/site-packages"
            - "spark-2.3.1-bin-hadoop2.7"
      - run:
          command: |
            . venv/bin/activate
            python test_scanpy_spark.py
      - store_test_results:
          path: test-results
      - store_artifacts:
          path: test-results
          destination: tr1
